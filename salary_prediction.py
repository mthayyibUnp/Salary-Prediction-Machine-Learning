# -*- coding: utf-8 -*-
"""Salary-Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Kdse5QWOrUg5Ko46my4mOLY4E-e_ScQj

Nama : Muhammad Thayyib

Dataset dari : https://www.kaggle.com/datasets/rkiattisak/salaly-prediction-for-beginer
"""

# Install kaggle package
!pip install -q kaggle

# Upload kaggle.json
from google.colab import files
files.upload()

# Make directory and change permission
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

# Test kaggle dataset list
!kaggle datasets list

# Download dataset from kaggle dataset
!kaggle datasets download -d rkiattisak/salaly-prediction-for-beginer

import zipfile
import os

# Path dataset ZIP yang diunduh
zip_file_path = "/content/salaly-prediction-for-beginer.zip"  # Ganti dengan path sesuai dengan file ZIP dataset yang diunduh

# Folder tempat untuk mengekstrak dataset
extracted_folder_path = "/content/salary_dataset"  # Ganti dengan path folder tempat Anda ingin mengekstrak dataset

# Mengekstrak file ZIP
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extracted_folder_path)

# Memeriksa isi dari folder ekstraksi
print(os.listdir(extracted_folder_path))

"""**Import Library yang Diperlukan**

Library yang diimpor digunakan untuk analisis data, visualisasi data, preprocessing data, dan pembuatan model.
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

# Memuat dataset ke dalam DataFrame
data = pd.read_csv("/content/salary_dataset/Salary Data.csv")

data.head()

"""**Data Exploration**

- Melihat informasi dasar dataset untuk memeriksa jenis data dan apakah ada nilai yang hilang.
- Menampilkan deskripsi statistik dari dataset untuk melihat ringkasan statistik dari setiap kolom.
- Memeriksa distribusi gaji dengan histogram.
- Menampilkan korelasi antar fitur numerik dengan heatmap.

"""

# Melihat informasi dasar dataset
print(data.info())

# Melihat statistik deskriptif dari dataset
print(data.describe())

# Melihat distribusi gaji dengan histogram
plt.figure(figsize=(10, 6))
sns.histplot(data['Salary'], bins=30, kde=True, color='blue')
plt.title('Distribution of Salary')
plt.xlabel('Salary')
plt.ylabel('Frequency')
plt.show()

# Melihat korelasi antar fitur numerik dengan heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

"""**Missing Values**

Mengecek dan menangani nilai yang hilang:

- Mengisi nilai yang hilang dengan rata-rata untuk fitur numerik.
- Mengisi nilai yang hilang dengan modus untuk fitur kategorikal.
"""

# Periksa missing values
missing_values = data.isnull().sum()
print("Missing values per column:\n", missing_values)

# Isi missing values dengan nilai rata-rata untuk fitur numerik
numeric_features = ['Age', 'Years of Experience']
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())])

# Isi missing values dengan nilai mode untuk fitur kategorikal
categorical_features = ['Gender', 'Education Level', 'Job Title']
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])

"""**Data Preprocessing**

- Menggunakan ColumnTransformer untuk menggabungkan preprocessing untuk fitur numerik dan kategorikal.
- Pisahkan variabel target dan fitur.
"""

# Gabungkan preprocessing dengan ColumnTransformer
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)])

# Pisahkan variabel target dan fitur
X = data.drop(columns=['Salary'])
y = data['Salary']

# Periksa dan tangani nilai NaN dalam variabel target
if y.isnull().any():
    print("Variabel target mengandung nilai NaN.")
    y = y.dropna()  # Hapus baris dengan nilai NaN
    X = X.dropna()  # Hapus baris yang sesuai dari fitur

"""**Split Dataset**

Membagi dataset menjadi data latih dan data uji dengan rasio 80:20.
"""

# Pisahkan dataset menjadi data latih dan data uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Definisikan pipeline model
model = Pipeline(steps=[('preprocessor', preprocessor),
                        ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))])

# Latih model
model.fit(X_train, y_train)

# Prediksi pada data uji
y_pred = model.predict(X_test)

# Evaluasi model menggunakan Mean Squared Error (MSE)
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)

# Visualisasi hasil prediksi
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred)
plt.xlabel("Actual Salary")
plt.ylabel("Predicted Salary")
plt.title("Actual vs Predicted Salary")
plt.show()